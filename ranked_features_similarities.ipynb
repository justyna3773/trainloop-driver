{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spca_ranking = [1,0,2,5,3,6,4]\n",
    "attention_ranking = [0,1,2,5,3,6,4]\n",
    "corr_ranking = [1,0,2,3,5,6,4]\n",
    "ig_ranking = [1,2,0,5,3,6,4]\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBO: 0.47670309999999994\n",
      "RBO: 0.45847809999999994\n",
      "RBO: 0.37670309999999996\n"
     ]
    }
   ],
   "source": [
    "def rbo(a, b, p=0.9):\n",
    "    # a, b are lists; p in (0,1): higher = more top-heavy persistence\n",
    "    import math\n",
    "    A, B = [], []\n",
    "    seen_a, seen_b = set(), set()\n",
    "    depth = min(len(a), len(b))\n",
    "    rbo_ext = 0.0\n",
    "    for d in range(1, depth+1):\n",
    "        seen_a.add(a[d-1]); seen_b.add(b[d-1])\n",
    "        overlap = len(seen_a & seen_b)\n",
    "        rbo_ext += (overlap / d) * (p ** (d-1))\n",
    "    return (1 - p) * rbo_ext\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "\n",
    "def kendall_tau_b_from_orders(a, b):\n",
    "    # a, b contain same items; map to ranks then τ-b\n",
    "    idx = {item:i for i,item in enumerate(a)}\n",
    "    r1 = [idx[x] for x in a]\n",
    "    r2 = [idx[x] for x in b]\n",
    "    return kendalltau(r1, r2).correlation\n",
    "\n",
    "def spearman_rho_from_orders(a, b):\n",
    "    idx = {item:i for i,item in enumerate(a)}\n",
    "    r1 = [idx[x] for x in a]; r2 = [idx[x] for x in b]\n",
    "    return spearmanr(r1, r2).correlation\n",
    "\n",
    "\n",
    "# print(\"RBO:\", rbo(spca_ranking, attention_ranking))\n",
    "# print(\"Kendall's τ-b:\", kendall_tau_b_from_orders(spca_ranking, attention_ranking))\n",
    "# print(\"Spearman's ρ:\", spearman_rho_from_orders(spca_ranking, attention_ranking))\n",
    "print(\"RBO:\", rbo(spca_ranking, ig_ranking))\n",
    "#print(\"Kendall's τ-b:\", kendall_tau_b_from_orders(spca_ranking, ig_ranking))\n",
    "#print(\"Spearman's ρ:\", spearman_rho_from_orders(spca_ranking, ig_ranking))\n",
    "\n",
    "print(\"RBO:\", rbo(corr_ranking, ig_ranking))\n",
    "print(\"RBO:\", rbo(attention_ranking, ig_ranking))\n",
    "\n",
    "#print(\"Kendall's τ-b:\", kendall_tau_b_from_orders(corr_ranking, ig_ranking))\n",
    "#print(\"Spearman's ρ:\", spearman_rho_from_orders(corr_ranking, ig_ranking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979219452029507\n",
      "0.9722639546600214\n",
      "0.9782710221704757\n",
      "0.9764527851303665\n",
      "0.8123119698022505\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ndcg_at_4(baseline, cand, feats=7, gains=\"linear\"):\n",
    "    # baseline, cand: lists like ['f3','f1','f5','f2']\n",
    "    # gains: \"linear\" (4,3,2,1) or \"exp\" (15,7,3,1)\n",
    "    if gains == \"linear\":\n",
    "        rel_map = {f: 4 - i for i, f in enumerate(baseline)}  # 4..1\n",
    "    else:\n",
    "        rel_map = {f: (2 ** (4 - i) - 1) for i, f in enumerate(baseline)}  # 15..1\n",
    "    # candidate relevance vector in its displayed order:\n",
    "    rel = np.array([rel_map.get(f, 0) for f in cand], dtype=float)\n",
    "    # DCG with log2 discount\n",
    "    dcg = (rel / np.log2(np.arange(2, len(cand) + 2))).sum()\n",
    "    # IDCG is DCG of the baseline (its own order)\n",
    "    ideal = np.array([rel_map[f] for f in baseline], dtype=float)\n",
    "    idcg = (ideal / np.log2(np.arange(2, len(baseline) + 2))).sum()\n",
    "    return float(dcg / idcg) if idcg > 0 else 0.0\n",
    "print(ndcg_at_4(spca_ranking, ig_ranking, gains=\"linear\"))\n",
    "#print(ndcg_at_4(attention_ranking, ig_ranking, gains=\"linear\"))\n",
    "print(ndcg_at_4(corr_ranking, ig_ranking, gains=\"linear\"))\n",
    "\n",
    "def ndcg_at_k(baseline, cand, k=7, gains=\"linear\"):\n",
    "    \"\"\"\n",
    "    baseline: ideal ranking, e.g. ['f3','f1','f5','f2', ...]\n",
    "    cand    : candidate ranking (same domain), e.g. ['f1','f2','f3', ...]\n",
    "    k       : cutoff (NDCG@k)\n",
    "    gains   : \"linear\" or \"exp\"\n",
    "    \"\"\"\n",
    "    if k <= 0 or len(baseline) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    m = min(k, len(baseline))  # how many ideal items we consider at cutoff\n",
    "\n",
    "    # relevance for the top-m items in the baseline\n",
    "    if gains == \"linear\":\n",
    "        rel_vals = [m - i for i in range(m)]                 # m, m-1, ..., 1\n",
    "    else:  # \"exp\"\n",
    "        rel_vals = [(2 ** (m - i) - 1) for i in range(m)]    # 2^m-1, ..., 1\n",
    "\n",
    "    rel_map = {f: r for f, r in zip(baseline[:m], rel_vals)}\n",
    "\n",
    "    # candidate relevance vector at cutoff k\n",
    "    rel = np.array([rel_map.get(f, 0) for f in cand[:k]], dtype=float)\n",
    "\n",
    "    # DCG@k with log2 discount\n",
    "    dcg = (rel / np.log2(np.arange(2, 2 + len(rel)))).sum()\n",
    "\n",
    "    # IDCG@k: ideal order is baseline[:m]\n",
    "    ideal = np.array(rel_vals, dtype=float)\n",
    "    idcg = (ideal / np.log2(np.arange(2, 2 + m))).sum()\n",
    "\n",
    "    return float(dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "print(ndcg_at_k(spca_ranking, ig_ranking, gains=\"exp\"))\n",
    "#print(ndcg_at_4(attention_ranking, ig_ranking, gains=\"linear\"))\n",
    "print(ndcg_at_k(corr_ranking, ig_ranking, gains=\"exp\"))\n",
    "print(ndcg_at_k(attention_ranking, ig_ranking, gains=\"exp\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard @4: 1.0\n",
      "Overlap Curve AUC: 0.7857142857142857\n",
      "Jaccard @4: 0.6\n",
      "Overlap Curve AUC: 0.75\n",
      "Jaccard @4: 1.0\n",
      "Overlap Curve AUC: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "def jaccard_at_k(a, b, k):\n",
    "    A, B = set(a[:k]), set(b[:k])\n",
    "    return len(A & B) / len(A | B) if A | B else 1.0\n",
    "\n",
    "def overlap_curve_auc(a, b, k_max=None):\n",
    "    n = min(len(a), len(b))\n",
    "    k_max = k_max or n\n",
    "    xs, ys = [], []\n",
    "    for k in range(1, k_max+1):\n",
    "        xs.append(k); ys.append(len(set(a[:k]) & set(b[:k])) / k)\n",
    "    # trapezoidal AUC normalized to [0,1]\n",
    "    import numpy as np\n",
    "    auc = np.trapz(ys, xs) / k_max\n",
    "    return auc, (np.array(xs), np.array(ys))\n",
    "# print(\"Jaccard @3:\", jaccard_at_k(spca_ranking, attention_ranking, 4))\n",
    "# auc, (xs, ys) = overlap_curve_auc(spca_ranking, attention_ranking)\n",
    "# print(\"Overlap Curve AUC:\", auc)\n",
    "\n",
    "print(\"Jaccard @4:\", jaccard_at_k(spca_ranking, ig_ranking, 4))\n",
    "auc, (xs, ys) = overlap_curve_auc(spca_ranking, ig_ranking)\n",
    "print(\"Overlap Curve AUC:\", auc)\n",
    "\n",
    "print(\"Jaccard @4:\", jaccard_at_k(corr_ranking, ig_ranking, 4))\n",
    "auc, (xs, ys) = overlap_curve_auc(corr_ranking, ig_ranking)\n",
    "print(\"Overlap Curve AUC:\", auc)\n",
    "\n",
    "print(\"Jaccard @4:\", jaccard_at_k(attention_ranking, ig_ranking, 4))\n",
    "auc, (xs, ys) = overlap_curve_auc(attention_ranking, ig_ranking)\n",
    "print(\"Overlap Curve AUC:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen metrics comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = [0,1,2]\n",
    "ig = [0,1,2]\n",
    "spca=[0,1,2,3,5]\n",
    "corr = [0,1,2,3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "def jaccard_list(a, b):\n",
    "    A, B = set(a), set(b)\n",
    "    if not A and not B:\n",
    "        return 1.0\n",
    "    return len(A & B) / len(A | B)\n",
    "print(jaccard_list(att,ig))\n",
    "print(jaccard_list(spca,ig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlaps of best random metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes: {'A': 5, 'B': 4, 'C': 4}\n",
      "All-sets intersection: {'2', '4'}\n",
      "A∩B: {'5', '2', '4'}\n",
      "Jaccard(A,B): 0.5\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations, product\n",
    "\n",
    "def compute_overlaps(named_sets):\n",
    "    \"\"\"\n",
    "    named_sets: dict[str, Iterable]  e.g. {\"v1\": [\"m1\",\"m2\"], \"v2\": {...}, ...}\n",
    "    Returns: sizes, pairwise_intersections, all_sets_intersection, jaccard_matrix\n",
    "    \"\"\"\n",
    "    S = {name: set(map(str, vals)) for name, vals in named_sets.items()}\n",
    "    sizes = {k: len(v) for k, v in S.items()}\n",
    "    all_intersection = set.intersection(*S.values()) if S else set()\n",
    "    pairwise = {tuple(sorted((a, b))): (S[a] & S[b]) for a, b in combinations(S, 2)}\n",
    "    jaccard = {\n",
    "        a: {b: (len(S[a] & S[b]) / len(S[a] | S[b]) if (S[a] or S[b]) else 0.0) for b in S}\n",
    "        for a in S\n",
    "    }\n",
    "    return sizes, pairwise, all_intersection, jaccard\n",
    "\n",
    "# Example\n",
    "# sets = {\n",
    "#     \"A\": {\"2\",\"3\",\"4\",\"5\", \"6\"},\n",
    "#     \"B\": {\"0\",\"2\",\"4\", \"5\"},\n",
    "#     \"C\": {\"1\",\"2\",\"3\",\"4\"},\n",
    "# }\n",
    "sets = {\n",
    "    \"A\": {\"2\",\"3\",\"4\",\"5\", \"6\"},\n",
    "    \"B\": {\"0\",\"2\",\"4\", \"5\"},\n",
    "    \n",
    "}\n",
    "sizes, pairwise, all_k, jaccard = compute_overlaps(sets)\n",
    "\n",
    "print(\"Sizes:\", sizes)\n",
    "print(\"All-sets intersection:\", all_k)                # metrics shared by ALL sets\n",
    "print(\"A∩B:\", pairwise[(\"A\",\"B\")])                    # pairwise overlap\n",
    "print(\"Jaccard(A,B):\", round(jaccard[\"A\"][\"B\"], 3))   # |A∩B| / |A∪B|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainloop_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
